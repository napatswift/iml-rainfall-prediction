<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
    />

    <title>reveal.js</title>

    <link rel="stylesheet" href="dist/reset.css" />
    <link rel="stylesheet" href="dist/reveal.css" />
    <link rel="stylesheet" href="dist/theme/serif.css" />

    <!-- Theme used for syntax highlighted code -->
    <link rel="stylesheet" href="plugin/highlight/monokai.css" />
  </head>

  <body>
    <div class="reveal">
      <div class="slides">
        <section>
          <p>üå¶Ô∏è</p>
          <h1>Rainfall Prediction in Bangkok</h1>
          <p>‚õàÔ∏è</p>
        </section>
        <section>
          <section>
            <iframe
              src="https://weather.bangkok.go.th/rain"
              width="80%"
              height="400px"
            ></iframe>
            <p style="font-size: small">
              The data used in this project was scraped from the
              <a href="https://weather.bangkok.go.th/rain" target="_blank"
                >Bangkok website</a
              >
            </p>
          </section>
          <section>
            <p>contains rainfall measurements for 311,211 rows</p>
            <p>from 02/01/2564 08:20 to 18/02/2566 16:50</p>
          </section>
        </section>
        <section data-auto-animate>
					<section>
						Main program
					</section>
					<section>
          <pre data-id="code-animation">
						<code data-line-numbers="2-4|13-14|7-10,13-14|16|18-20|24-29|33|38-39|41|41-42">
df = pd.concat([pd.read_csv(
		os.path.join('data', p)
) for p in os.listdir('data')])  # .sample(2_000)


def replace_year(string):
		y = string[6:10]
		y = str(int(y) - 543)
		return string[:6] + y + string[10:]


df.loc[:, 'time'] = pd.to_datetime(
		df['‡∏ß‡∏±‡∏ô-‡πÄ‡∏ß‡∏•‡∏≤'].apply(replace_year), format='%d/%m/%Y %H:%M')

df = df.sort_values('time')

grouped = df.groupby(
		['‡πÄ‡∏Ç‡∏ï', pd.Grouper(key="time", freq='30min')]
)['‡∏ù‡∏ô 30 ‡∏ô‡∏≤‡∏ó‡∏µ'].max()

prev_time_len = 5
chunks = []
for i in trange(len(grouped.index)-prev_time_len, desc='Building data chunks'):
		if not grouped[i:i+prev_time_len].isna().any():
				indices = grouped[i:i+prev_time_len].index
				chunks.append(
						grouped[indices].values
				)

print('Total data points is', len(chunks))

data = np.array(chunks)

X = data[:, :prev_time_len-1]
y = data[:, prev_time_len-1]

X_train, X_test, y_train, y_test = train_test_split(
		X, y, test_size=0.2)

my_reg = MyLinearRegression(0.0003)\
	.fit(X_train, y_train, iteration=8000)

print('Mean absolute error', mean_absolute_error(my_reg.predict(X_test), y_test))
					</code>
				</pre>
        </section>
        </section>
        <section>
					<section>
						The <code>train_test_split</code> function
					</section>
          <section>
            <pre>
<code data-line-numbers="1|2|6|7-8|9|10-13|15-16|6|18-21|23">def train_test_split(X, y, test_size=0.1):
		hist, bin_adges = np.histogram(y, bins='auto')

		train_mask = []
		test_mask = []
		for i, edge in enumerate(bin_adges):
				if i == 0:
						continue
				indices, = np.where((bin_adges[i - 1] <= y) & (y < edge))
				num_test = int(len(indices) * test_size)
				np.random.shuffle(indices)
				test_indices = indices[:num_test]
				train_indices = indices[num_test:]

				train_mask += list(train_indices)
				test_mask += list(test_indices)

		X_train = X[train_mask]
		X_test = X[test_mask]
		y_train = y[train_mask]
		y_test = y[test_mask]

		return X_train, X_test, y_train, y_test</code></pre>
          </section>
        </section>

				<section>
					<section>Linear Regression Model</section>
					<section>
						<pre>
<code data-line-numbers="4-8|11-43|46-69|71-91|93-103|105-118|11|25|28|37|40|40-41|46|57|71|82|84|85|87|89|91|57|60,63|93|103|40|43">class MyLinearRegression:
    
	# Class constructor
	def __init__(self, alpha=1):
			self.alpha = alpha
			self.w = None
			self.w_dim = None
			self.losses = None
			

	def fit(self, x: np.ndarray, y: np.ndarray, iteration=1500):
			"""
			Fit the linear regression model to the given data.

			Parameters:
			x (numpy.ndarray): The input features.
			y (numpy.ndarray): The target values.
			iteration (int): The number of iterations for training. Default is 1500.

			Returns:
			self (MyLinearRegression): The fitted linear regression model.
			"""

			# Set the target values
			self.y = y

			# Determine the dimension of the weight vector
			self.w_dim = x.shape[-1] + 1  # plus one for bias

			# Initialize the weight vector with zeros
			self.w = np.zeros(self.w_dim)

			# Append a column of ones to the input features for the bias term
			self.x = np.append(x, np.ones((x.shape[0], 1)), axis=1)

			# Initialize an array to store the losses for each iteration
			self.losses = np.ones(iteration)

			# Perform gradient descent for the specified number of iterations
			for i in range(iteration):
					self.losses[i] = self._make_one_update()

			return self
			

	def _make_one_update(self):
			"""
			Perform one update step of gradient descent.

			Returns:
			float: The loss after the update step.
			"""
			# Make a copy of the current weight vector
			w_current = self.w.copy()

			# Compute the step size using the learning rate and the gradient
			step = -1 * self.alpha * self._compute_gradient(w_current)

			# Update the weight vector
			w_update = w_current + step

			# Calculate the loss after the update
			update_loss = self.sq_loss(w_update)

			# Update the weight vector with the new values
			self.w = w_update

			# Return the loss after the update
			return update_loss
	
	def _compute_gradient(self, w_current: np.ndarray):
			"""
			Compute the gradient of the loss function with respect to the weight vector.

			Parameters:
			w_current (numpy.ndarray): The current weight vector.

			Returns:
			numpy.ndarray: The computed gradient.
			"""

			grad_v = np.zeros(self.w_dim)

			predictions = self.x @ w_current
			errors = self.y - predictions

			grad_v[:-1] = -2 / self.x.shape[0] * np.sum(self.x[:, :-1] * errors[:, None], axis=0)

			grad_v[-1] = -2 / self.x.shape[0] * np.sum(predictions)

			return grad_v / math.sqrt(np.inner(grad_v, grad_v))

	def sq_loss(self, w: np.ndarray) -> float:
			"""
			Calculates the squared loss for linear regression.

			Parameters:
			w (numpy.ndarray): the weight vector

			Returns:
			float: the mean squared loss
			"""
			return np.mean((self.y - self.x @ w)**2)

	def predict(self, X:  np.ndarray):
			"""
			Predicts using linear regression model

			Parameters:
			X (numpy.ndarray): features

			Returns:
			numpy.ndarray: predicted values
			"""

			x = np.append(X.copy(), np.ones((X.shape[0], 1)), axis=1)

			return x @ self.w
</code>
						</pre>
					</section>
				</section>

				<section>
					<p>Training Loss (Mean squared error)</p>
					<img src="images/trainingloss-graph.png" width="300px" alt="Training loss" srcset="">
				</section>

				<section>
					<span style="font-size:medium;">Result</span>
					<p>Mean absolute error <strong>3.473</strong></p>
				</section>
      </div>
    </div>

    <script src="dist/reveal.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script>
      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
        hash: true,

        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [RevealMarkdown, RevealHighlight, RevealNotes],
      });
    </script>
  </body>
</html>
